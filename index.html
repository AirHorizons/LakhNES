<html>
	<head>
		<title>LakhNES Sound Examples</title>
<style>

#userstudy audio {
	width: 300px;
}
</style>

	</head>
	<body>

	<h1>Sound examples from <i>LakhNES</i></h1>

	<img src="logo.png" height="200px"/>

	<h2 id="authors">
		<a href="https://chrisdonahue.com">Chris Donahue</a>,
		<a href="https://henry.calclavia.com/">Huanru Henry Mao</a>,
		<a href="https://www.linkedin.com/in/ethanleet">Yiting Ethan Li</a>,
		<a href="https://cseweb.ucsd.edu/~gary/">Garrison W. Cottrell</a>,
		<a href="https://cseweb.ucsd.edu/~jmcauley/">Julian McAuley</a>
	</h2>

	<p>
	This web repository contains sound examples from our paper <i>LakhNES: Improving multi-instrumental music generation with cross-domain pre-training</i>. <b>This work is currently under double-blind review, please do not share this link with anyone</b>.
	</p>

	<h3>Chiptunes generated by LakhNES</h3>

	<p>This section showcases <i>unconditional</i> examples from our LakhNES model, i.e. chiptunes generated from scratch.</p>

	<table id="unconditional">
		<tr>
			<td><audio m="unconditional/d9eb5a019bdf46ef916dc1aba03d8505"></td>
			<td><audio m="unconditional/8ede1d2ba8a24e048f17e45d021a281c"></td>
			<td><audio m="unconditional/a87bb8d9624a42b7a38744bcde27e9e4"></td>
			<td><audio m="unconditional/1c08d3ef50f84bd998f0961c0e8ae2aa"></td>
		</tr>

		<tr>
			<td><audio m="unconditional/13da07cd13bb4928a355e8aa5baaa9c7"></td>
			<td><audio m="unconditional/e07f1a5667c84097a209c24a984dc765"></td>
			<td><audio m="unconditional/fce045bf4cfb4ce99fec0678aa21380c"></td>
			<td><audio m="unconditional/ec5ff957776848419f292708c750d0df"></td>
		</tr>

		<tr>
			<td><audio m="unconditional/f2ac3482268a497ca94e0373c15ac3a6"></td>
			<td><audio m="unconditional/c5b3a8e6966e44f3a08558a8005edb75"></td>
			<td><audio m="unconditional/810eb476381749808128fa395514e6a4"></td>
			<td><audio m="unconditional/c406ba97b7e2465dae8d8b2555a9e904"></td>
		</tr>

		<tr>
			<td><audio m="unconditional/7d609f53a91a4d94a5b52cc545f6c0ab"></td>
			<td><audio m="unconditional/c3f809cbe31740b69a8c4896bcaaf02d"></td>
			<td><audio m="unconditional/5fd439e533dd4167b5d4d5e00e86cafc"></td>
			<td><audio m="unconditional/762987ad44044b0e90b5755ee49348f8"></td>
		</tr>

		<tr>
			<td><audio m="unconditional/ba6ba272133341b2911cd48238b7f6a9"></td>
			<td><audio m="unconditional/a3d0e8bf5edd4b3eb5c58188dc7fdf36"></td>
			<td><audio m="unconditional/c8a7c40baf5e4f6eaf34fe212bcb41c0"></td>
			<td><audio m="unconditional/dcefca3c98c74f70b2fcaa1e4b089aba"></td>
		</tr>

	</table>

	<h3>Continuations of human-composed chiptunes</h3>

	<p>This section showcases examples of our model continuing human-composed material. We do this by feeding a snippet of a human-composed song that the model has never seen during training, and asking LakhNES to continue the piece.</p>

	<table id="primes">
		<tr>
			<th>Game</th>
			<th>Priming sequence</th>
			<th>LakhNES Continuation 1</th>
			<th>LakhNES Continuation 2</th>
			<th>Human Continuation</th>
		</tr>
		<tr>
			<td>Bubble Bobble</td>
			<td><audio p="primes/038_BubbleBobble_04_05SuperDrunk_prime"></td>
			<td><audio p="primes/038_BubbleBobble_04_05SuperDrunk_cont_057e"></td>
			<td><audio p="primes/038_BubbleBobble_04_05SuperDrunk_cont_df65"></td>
			<td><audio p="primes/038_BubbleBobble_04_05SuperDrunk_full"></td>
		</tr>
		<tr>
			<td>Bubble Bobble</td>
			<td><audio p="primes/038_BubbleBobble_02_03SecretRoom_prime"></td>
			<td><audio p="primes/038_BubbleBobble_02_03SecretRoom_cont_20db"></td>
			<td><audio p="primes/038_BubbleBobble_02_03SecretRoom_cont_1a57"></td>
			<td><audio p="primes/038_BubbleBobble_02_03SecretRoom_full"></td>
		</tr>
		<tr>
			<td>Operation Wolf</td>
			<td><audio p="primes/256_OperationWolf_00_01OpeningDemo_prime"></td>
			<td><audio p="primes/256_OperationWolf_00_01OpeningDemo_cont_d85d"></td>
			<td><audio p="primes/256_OperationWolf_00_01OpeningDemo_cont_9df6"></td>
			<td><audio p="primes/256_OperationWolf_00_01OpeningDemo_full"></td>
		</tr>
		<tr>
			<td>Vs. Duck Hunt</td>
			<td><audio p="primes/374_Vs_DuckHunt_06_07BreakTime_prime"></td>
			<td><audio p="primes/374_Vs_DuckHunt_06_07BreakTime_cont_cce8"></td>
			<td><audio p="primes/374_Vs_DuckHunt_06_07BreakTime_cont_0549"></td>
			<td><audio p="primes/374_Vs_DuckHunt_06_07BreakTime_full"></td>
		</tr>
		<tr>
			<td>The Battle of Midway</td>
			<td><audio p="primes/002_1943_TheBattleofMidway_14_15EnergyEmpty_prime"></td>
			<td><audio p="primes/002_1943_TheBattleofMidway_14_15EnergyEmpty_cont_01d2"></td>
			<td><audio p="primes/002_1943_TheBattleofMidway_14_15EnergyEmpty_cont_5043"></td>
			<td><audio p="primes/002_1943_TheBattleofMidway_14_15EnergyEmpty_full"></td>
		</tr>
	</table>

	<h3>Generating with human-specified rhythm</h3>

	<p>It would be useful if our generative model could assist in human-guided composition. Here, we condition LakhNES on the rhythm from a human-composed song and ask it to fill in the notes.</p>
	
	<table id="rhythm">

		<tr>
			<th>Game</th>
			<th>Rhythm specification</th>
			<th>LakhNES Notes 1</th>
			<th>LakhNES Notes 2</th>
			<th>Human notes</th>
		</tr>

		<tr>
			<td>Choplifter</td>
			<td><audio p="rhythms/052_Choplifter_00_01TitleScreen_rhythm"></td>
			<td><audio p="rhythms/052_Choplifter_00_01TitleScreen_jamrhythm_34d4"></td>
			<td><audio p="rhythms/052_Choplifter_00_01TitleScreen_jamrhythm_a58e"></td>
			<td><audio p="rhythms/052_Choplifter_00_01TitleScreen_full"></td>
		</tr>
	
		<tr>
			<td>Digital Devil Story</td>
			<td><audio p="rhythms/071_DigitalDevilStory_MegamiTensei_02_03MicomStartingMicomCity_rhythm"></td>
			<td><audio p="rhythms/071_DigitalDevilStory_MegamiTensei_02_03MicomStartingMicomCity_jam_c8cc"></td>
			<td><audio p="rhythms/071_DigitalDevilStory_MegamiTensei_02_03MicomStartingMicomCity_jam_ecbf"></td>
			<td><audio p="rhythms/071_DigitalDevilStory_MegamiTensei_02_03MicomStartingMicomCity_full"></td>
		</tr>

		<tr>
			<td>Dragon Buster II</td>
			<td><audio p="rhythms/085_DragonBusterII_YaminoFuuin_03_04ForestRound12_rhythm"></td>
			<td><audio p="rhythms/085_DragonBusterII_YaminoFuuin_03_04ForestRound12_jam_0058"></td>
			<td><audio p="rhythms/085_DragonBusterII_YaminoFuuin_03_04ForestRound12_jam_f7b5"></td>
			<td><audio p="rhythms/085_DragonBusterII_YaminoFuuin_03_04ForestRound12_full"></td>
		</tr>

		<tr>
			<td>Terra Cresta</td>
			<td><audio p="rhythms/338_TerraCresta_10_11Unknown_rhythm"></td>
			<td><audio p="rhythms/338_TerraCresta_10_11Unknown_jam_2e90"></td>
			<td><audio p="rhythms/338_TerraCresta_10_11Unknown_jam_bbe4"></td>
			<td><audio p="rhythms/338_TerraCresta_10_11Unknown_full"></td>
		</tr>

	</table>

	<h3>Non-cherry-picked examples from all models</h3>

	<p>In this section we show uncurated collections of 8 sound examples from each model included in our user study. This is intended to both contextualize the results of our user study <i>and</i> speak to the general capabilities of each model.</p>

	<table id="userstudy">
		<tr>
			<th>Method</th>
			<th>Example 1</th>
			<th>Example 2</th>
			<th>Example 3</th>
			<th>Example 4</th>
			<th>Example 5</th>
			<th>Example 6</th>
			<th>Example 7</th>
			<th>Example 8</th>
		</tr>
		<tr>
			<td>Random (control)</td>
			<td><audio p="userstudy/0072e5399bff43d2a53fb5fdde9795df"></td>
			<td><audio p="userstudy/04fd7dbfa82e48cd95f3296e179fc954"></td>
			<td><audio p="userstudy/192c980b5c9f481a9f45bb63ffc3a96c"></td>
			<td><audio p="userstudy/403ca26618bc4cd3a2c9b8497aca9ba7"></td>
			<td><audio p="userstudy/5e5506481b9141bcb6add0fa21b47c76"></td>
			<td><audio p="userstudy/6695c8b72945471fa2941aeb1d4146c3"></td>
			<td><audio p="userstudy/b1a51aad982b40b9b33838360aafe9b9"></td>
			<td><audio p="userstudy/dfdd68268bad49fbb6df571d2bc7bef6"></td>
		</tr>
		<tr>
			<td>5-gram</td>
			<td><audio p="userstudy/316c6f2f5a3c4e6ba1d1ebda490ae554"></td>
			<td><audio p="userstudy/466d76d494784b02b5dbdb0319085cea"></td>
			<td><audio p="userstudy/591b61a84b824fa8a660e40dba35afd4"></td>
			<td><audio p="userstudy/59b3f3c8e75e4fd5a0412fd0b8e004dd"></td>
			<td><audio p="userstudy/5e5a001f44b64ad08fd068e299f60a87"></td>
			<td><audio p="userstudy/73fd506eb92940988d1e5561ab371fb5"></td>
			<td><audio p="userstudy/cd2749f5e2054a0aa3de53c290295470"></td>
			<td><audio p="userstudy/e10c02934d3343aea52355b766c0d02b"></td>
		</tr>
		<tr>
			<td>LSTM</td>
			<td><audio p="userstudy/0e70db1407074673b83e14c120ef5930"></td>
			<td><audio p="userstudy/1c3e729d04e94897a1155e7b15fc74b4"></td>
			<td><audio p="userstudy/209068e4f37145538ed71d421424d4da"></td>
			<td><audio p="userstudy/38176485fd6d4c2d9b01b73eb0fab4d7"></td>
			<td><audio p="userstudy/8898be3641d74e44b4c36eba9737a8ba"></td>
			<td><audio p="userstudy/9dc98583556e4c73a20f2b79086ce608"></td>
			<td><audio p="userstudy/b53f9ff8e5e84f37bf0681afd216df09"></td>
			<td><audio p="userstudy/df964b262f1743d58cd91b59c7422ec1"></td>
		</tr>
		<tr>
			<td>Transformer-XL</td>
			<td><audio p="userstudy/0cfa1188f4a74e399c38d9622eee57d8"></td>
			<td><audio p="userstudy/123e166e8ac8480bb1075d7eaac4bfd8"></td>
			<td><audio p="userstudy/2bfce8efd3274259b1b0e10e4c5fdb5b"></td>
			<td><audio p="userstudy/3689e608d31e41ea938942f425100d58"></td>
			<td><audio p="userstudy/401ddb5e98fd4b9f932e1c68d1e0865f"></td>
			<td><audio p="userstudy/40d9f4acb1204a0f876a59155d68c792"></td>
			<td><audio p="userstudy/b04889d204b1428b8ef2219da340c9e3"></td>
			<td><audio p="userstudy/fe5109ebf4134834839bf4e87d2aba59"></td>
		</tr>
		<tr>
			<td>LakhNES</td>
			<td><audio p="userstudy/004c4befde8b43acb2f1a9b4325f56dd"></td>
			<td><audio p="userstudy/05a1ba0438894ec3b767b289e873cb1c"></td>
			<td><audio p="userstudy/14065600e2d540de91315e6d846de53e"></td>
			<td><audio p="userstudy/27d61f9cfc6c47acb8c7397240d8ffe2"></td>
			<td><audio p="userstudy/41e7f1559a6c4001b68bf2544ede8cc5"></td>
			<td><audio p="userstudy/5606a1bd666e4d9a8bca96462d6bf871"></td>
			<td><audio p="userstudy/8383f4edae074cccbd9d031374ead568"></td>
			<td><audio p="userstudy/8a4a1dbad7234ec9b2ef8c6465ab9e68"></td>
		</tr>
		<tr>
			<td>Real data</td>
			<td><audio p="userstudy/1ea72b562628449b826c3320f1e2f73d"></td>
			<td><audio p="userstudy/3105be6188cb41068119912ae7f386be"></td>
			<td><audio p="userstudy/62f9f5378ba448a49824be9ad28358bb"></td>
			<td><audio p="userstudy/712c9fdec24e4341a9ce3c4d85d6b13d"></td>
			<td><audio p="userstudy/74fa601b33154e5bad44afeb94a1c0a7"></td>
			<td><audio p="userstudy/c016f0e3904745cb86b0565730638964"></td>
			<td><audio p="userstudy/c334be7aadf746469e015a451e013018"></td>
			<td><audio p="userstudy/cd6a0a41789b47979a54f1e1c6a6e0fb"></td>
		</tr>
	</table>

	</body>

<script>
var atmpl = '<audio class="rendered" controls><source src="SRCHERE" type="audio/mpeg">Your browser does not support the audio tag :(</audio>';

var audios = document.body.getElementsByTagName('audio');
for (var i = 0; i < audios.length; ++i) {
	var oldEl = audios[i];
	var actualSource;
	if (oldEl.hasAttribute('p')) {
		actualSource = '' + oldEl.getAttribute('p') + '.mp3';
	} else {
		actualSource = '' + oldEl.getAttribute('m') + '.tx1.mp3';
	}

	var newEl = document.createElement('div');
	newEl.innerHTML = atmpl.replace('SRCHERE', actualSource);

	oldEl.parentNode.replaceChild(newEl, oldEl);
}
</script>

</html>
